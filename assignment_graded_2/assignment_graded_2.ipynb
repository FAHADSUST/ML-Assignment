{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logo.png\" style=\"width: 100px;\"/>\n",
    "<h1><center>Graded Assignment 2 Solution</center></h1>\n",
    "\n",
    "<center>Due: 12.02.2021, 23:59</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to upload:\n",
    "\n",
    "Upload your solution via the VC course. Please upload **one Zip archive** per group. The Zip must contain:\n",
    "* Your solution **notebook** (a **.ipynb** file)\n",
    "* A Prolog script file (see task 1)\n",
    "* An **images folder** with all your images (keep the size of the images relatively small)\n",
    "* A **data folder** with the datasets (you probably don't have to change anything here)\n",
    "\n",
    "Your Zip should be named after the following scheme:\n",
    "\n",
    "* assignment_graded\\_**2**_solution.zip\n",
    "\n",
    "__NOTE: This assignment will be graded and you can receive bonus points for the exam.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Metagol  (13 points)\n",
    "\n",
    "For this task we will use the ILP framework Metagol. Please see [here](https://cogsys.uni-bamberg.de/teaching/ws1920/ml/practice/metagol_intro.pdf)\n",
    "for an introduction to the system. In order to run Prolog script files, you also need a Prolog interpreter. We suggest SWI-Prolog, which can be found [here](https://www.swi-prolog.org/).\n",
    "\n",
    "The task will consist of learning FOL rules for the concept of \"female ancestor\". We can describe this relationship by the following two rules (Two separate rules can be seen as being disjunctive - either the first __OR__ the second rule has to hold). Note that the second rule is recursive.\n",
    "\n",
    "$\\text{target}(A, B) \\leftarrow \\text{female}(A) \\wedge \\text{parent}(A, B)$\n",
    "\n",
    "$\\text{target}(A, B) \\leftarrow \\text{female}(A) \\wedge \\text{parent}(C, B) \\wedge \\text{target}(A, C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you find an excerpt of family relations. An arrow means that the corresponding persons are in a __parent__ relationship ($parent \\rightarrow child$). Ellipses denote females and rectangles denote males:\n",
    "\n",
    "<img src=\"images/family_tree.png\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You find the start of a Metagol-Prolog-file in the VC course. The\n",
    "information whether a person is female is already given as background knowledge. All males are just considered not females. The Closed World Assumption holds; therefore we do not have to explicitely state that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1.1) (4 points):__ Complete the background knowledge by stating the parental information as Prolog facts. Use __parent__ as the predicate name for parents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1.2) (4 Points):__ State (a) metarule(s) for the task of learning \"female ancestor\". Think about the different rules that describe this relation. How does the head of the rules have to look like? What are the body literals and how are they connected via variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1.3) (3 Points):__ Now for the learning task: Incorporate all possible positive examples in the respective slot. Use the predicate name __target__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1.4) (2 Points):__ The power of ILP lies in the capability of generalizing from very few but expressive examples. So it is actually possible to only state **one negative example** (given that we already stated all positive examples in the last task) to learn the task. So find an example (and only one, otherwise you get no points on this task) and run the Prolog script. See if the correct two rules are getting induced. Then make a screenshot and paste it here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your screenshot goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2) Instance Based Learning (28.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.1) (1 point):__ In the lecture slides to Instance Based Learning on page 2, Instance-based learning is also called Lazy Learning. Can you give an explanation as to why this term may be accurate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:Instance-based methods are referred to as lazy learning methods because they delay processing until a new instance must be classified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.2) (1 point)__: Give an example use case where an instance based approach would excel at and explain why this is a proper problem for using instance based learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Instace based alogorithm is one of the most popular methods for text categorization. A newly text can be easily classified by messuring the value with pre-uploaded data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.3) (1.5 point)__: Give an example use case where an instance based approach would be inferior and explain why this is a improper problem for instance based learning. Which learning approach would you propose for your use case instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:If there are imbalance of data in any text categirization, then instance based learning can be inferior as these types of dataset can open create bias in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease prediction\n",
    "The following code loads and displays the heart disease dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Heart Dataset:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>male</td>\n",
       "      <td>severe</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>fbs &gt; 120mg/dl</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>no angina</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>male</td>\n",
       "      <td>major</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>fbs &lt; 120mg/dl</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>no angina</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>female</td>\n",
       "      <td>minor</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>fbs &lt; 120mg/dl</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>no angina</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>male</td>\n",
       "      <td>minor</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>fbs &lt; 120mg/dl</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>no angina</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>female</td>\n",
       "      <td>none</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>fbs &lt; 120mg/dl</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>angina</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>male</td>\n",
       "      <td>none</td>\n",
       "      <td>140</td>\n",
       "      <td>192</td>\n",
       "      <td>fbs &lt; 120mg/dl</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>no angina</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>female</td>\n",
       "      <td>minor</td>\n",
       "      <td>140</td>\n",
       "      <td>294</td>\n",
       "      <td>fbs &lt; 120mg/dl</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>no angina</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex      cp  trestbps  chol             fbs  restecg  thalach  \\\n",
       "0   63    male  severe       145   233  fbs > 120mg/dl        0      150   \n",
       "1   37    male   major       130   250  fbs < 120mg/dl        1      187   \n",
       "2   41  female   minor       130   204  fbs < 120mg/dl        0      172   \n",
       "3   56    male   minor       120   236  fbs < 120mg/dl        1      178   \n",
       "4   57  female    none       120   354  fbs < 120mg/dl        1      163   \n",
       "5   57    male    none       140   192  fbs < 120mg/dl        1      148   \n",
       "6   56  female   minor       140   294  fbs < 120mg/dl        0      153   \n",
       "\n",
       "       exang  oldpeak  slope  ca  target  \n",
       "0  no angina      2.3      0   0       1  \n",
       "1  no angina      3.5      0   0       1  \n",
       "2  no angina      1.4      2   0       1  \n",
       "3  no angina      0.8      2   0       1  \n",
       "4     angina      0.6      2   0       1  \n",
       "5  no angina      0.4      1   0       1  \n",
       "6  no angina      1.3      1   0       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "data = pd.read_csv(\"data/heart.csv\")\n",
    "display(HTML(\"<h3>Heart Dataset:</h3>\"))\n",
    "display(data.head(7))\n",
    "\n",
    "y_data = data[\"target\"]\n",
    "x_data = data.drop(\"target\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __\"target\"__ attribute encodes the presence of a heart disease in the patient.\n",
    "\n",
    "1. __age__: age\n",
    "2. __sex__: sex\n",
    "3. __cp__: chest pain type (4 values)\n",
    "4. __trestbps__: resting blood pressure\n",
    "5. __chol__: serum cholestoral in mg/dl\n",
    "6. __fbs__: fasting blood sugar > 120 mg/dl\n",
    "7. __restecg__: resting electrocardiographic results (3 values)\n",
    "8. __thalach__: maximum heart rate achieved\n",
    "9. __exang__: exercise induced angina\n",
    "10. __oldpeak__: oldpeak = ST depression induced by exercise relative to rest\n",
    "11. __slope__: the slope of the peak exercise ST segment\n",
    "12. __ca__: number of major vessels (0-4) colored by flourosopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.4) (3 points)__: Transform the data. Take a look at the data description and the data itself. Then preprocess the data so you can do some instance-based learning with it. Make sure to not increase the dimensionality too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>cp_minor</th>\n",
       "      <th>cp_none</th>\n",
       "      <th>cp_severe</th>\n",
       "      <th>fbs_fbs &gt; 120mg/dl</th>\n",
       "      <th>exang_no angina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.952197</td>\n",
       "      <td>0.763956</td>\n",
       "      <td>-0.256334</td>\n",
       "      <td>-1.005832</td>\n",
       "      <td>0.015443</td>\n",
       "      <td>1.087338</td>\n",
       "      <td>-2.274579</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.915313</td>\n",
       "      <td>-0.092738</td>\n",
       "      <td>0.072199</td>\n",
       "      <td>0.898962</td>\n",
       "      <td>1.633471</td>\n",
       "      <td>2.122573</td>\n",
       "      <td>-2.274579</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.474158</td>\n",
       "      <td>-0.092738</td>\n",
       "      <td>-0.816773</td>\n",
       "      <td>-1.005832</td>\n",
       "      <td>0.977514</td>\n",
       "      <td>0.310912</td>\n",
       "      <td>0.976352</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.180175</td>\n",
       "      <td>-0.663867</td>\n",
       "      <td>-0.198357</td>\n",
       "      <td>0.898962</td>\n",
       "      <td>1.239897</td>\n",
       "      <td>-0.206705</td>\n",
       "      <td>0.976352</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.290464</td>\n",
       "      <td>-0.663867</td>\n",
       "      <td>2.082050</td>\n",
       "      <td>0.898962</td>\n",
       "      <td>0.583939</td>\n",
       "      <td>-0.379244</td>\n",
       "      <td>0.976352</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  trestbps      chol   restecg   thalach   oldpeak     slope  \\\n",
       "0  0.952197  0.763956 -0.256334 -1.005832  0.015443  1.087338 -2.274579   \n",
       "1 -1.915313 -0.092738  0.072199  0.898962  1.633471  2.122573 -2.274579   \n",
       "2 -1.474158 -0.092738 -0.816773 -1.005832  0.977514  0.310912  0.976352   \n",
       "3  0.180175 -0.663867 -0.198357  0.898962  1.239897 -0.206705  0.976352   \n",
       "4  0.290464 -0.663867  2.082050  0.898962  0.583939 -0.379244  0.976352   \n",
       "\n",
       "         ca  sex_male  cp_minor  cp_none  cp_severe  fbs_fbs > 120mg/dl  \\\n",
       "0 -0.714429         1         0        0          1                   1   \n",
       "1 -0.714429         1         0        0          0                   0   \n",
       "2 -0.714429         0         1        0          0                   0   \n",
       "3 -0.714429         1         1        0          0                   0   \n",
       "4 -0.714429         0         0        1          0                   0   \n",
       "\n",
       "   exang_no angina  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "string_columns = [\n",
    "    \"sex\", \"cp\", \"fbs\",\n",
    "    \"exang\"\n",
    "]\n",
    "# List of all numerical features\n",
    "numerical_columns = [\n",
    "    \"age\", \"trestbps\",\n",
    "    \"chol\", \"restecg\", \"thalach\", \"oldpeak\", \"slope\", \"ca\"\n",
    "]\n",
    "\n",
    "x_data2 = pd.get_dummies(x_data, columns=string_columns, drop_first=True)\n",
    "\n",
    "scaled_features = x_data2.copy()\n",
    "features = scaled_features[numerical_columns]\n",
    "\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "\n",
    "scaled_features[numerical_columns] = features\n",
    "\n",
    "\n",
    "scaled_features.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.5) (1 point)__: Why is it so important to reduce the dimensionality for knn algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.6) (1 point):__ What does the k in k-nearest-neighbour stand for? How would you choose a value for k? How can you be sure your choice for k is a valid choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.7) (2 points):__ Explain what is meant by _cross validation_ in terms of model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.8) (4 points):__ Now it's time to train our k-nearest-neighbour model.\n",
    "- Use cross validation to determine the accuracy on 10 folds.\n",
    "- Also find the best hyperparameter combinations of the following two parameters:\n",
    "    - k: 1-25\n",
    "    - weights: \"uniform\", \"distance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing\n",
    "In this part, we will take a look at how to apply the theory behind instance-based learning to text data. The goal behind this is to give you an outlook on what else can be possible with relatively straightforward classification algorithms apart from simple classifications. ;)\n",
    "\n",
    "To do this, we need to download and import a new package called _gensim_. _Gensim_ is a powerful text-processing library with a repository of pre-trained models, which we can use.\n",
    "\n",
    "__Troubleshooting__: As _gensim_ can download text corpora and text processing models from their repository through a function call, an error could occur when you try to import it. To fix that you can manually install the library _smart_open_ at version _2.0.0_. This should resolve the problem.\n",
    "- conda install smart_open==2.0.0\n",
    "- pip install smart_open==2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.9) (3 points):__ Research on your own, what __Word Embeddings__ are, what they are used for and how they are created. Briefly explain this in your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will dowload a Word2Vec model named [_glove_](https://github.com/RaRe-Technologies/gensim-data), which was trained on part with the wikipedia text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this code does not work, try installing  smart_open==2.0.0\n",
    "import gensim.downloader as api\n",
    "word2vec = api.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.10) (0.5 point)__: What is the word embedding for the word _woman_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.11) (1 point)__: What are the most similar words to the words _king_ and _queen_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.12) (1.5 point)__: What is a good metric to determine the similarity of words in this representation? Briefly explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One advantage of context-based word embeddings is the fact that you can do basic arithmetic operations on them like summation or subtraction and still achieving \"somewhat\" sound results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.13) (1 point)__: Try this out by creating the sum of the words: _king_ and _woman_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.14) (2 points)__: Try to validate your result by calculating the similarity of your result to the word queen. You could do this with the similarity metric that you explained in Task 2.12). Does the sum of Task 2.13) make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads a small dataset with __23__ words from __3__ word-fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_csv(\"data/words.csv\")\n",
    "words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.15) (2 points)__: Transform the dataset so you can use it with a KNN algorithm. To do so, transform the words into a vector representation with the help of the word2vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.16) (3 points):__ Now create a word field classifier. Test your classifier with the three test cases: reign (field 1), motor (field 2), and jaguar (field 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Reinforcement Learning (23 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've seen 'Q-Learning' in a basic grid world as a way of reinforcement learning. In this task, you'll implement basic Q-Learning in a slightly more complicated scenario.\n",
    "\n",
    "### The Scenario\n",
    "Our agent is a Mars Rover, exploring the surface of the planet and performing science experiments. The rover has a base station for recharging the batteries.   \n",
    "Mars is represented as a grid world (8x8). There are big stones, which we can climb over, but that's pretty dangerous and should be avoided. Some areas are also rocky, but less problematic. Some grids are entirely free of obstacles.   \n",
    "The rover can move left, right, up, or down.\n",
    "\n",
    "<img src=\"images/Scenario.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "Currently, we are underway, and want to return to our base station. Our current position is marked by \"**S**\". Our target (the base station) is marked by \"**T**\". On one spot, we have an opportunity to do another science experiment, marked by \"**Bonus**\". Our target is to find a short way to our base station which maximizes the amount of science without running into obstacles. Ideally, we do not visit a state twice.   \n",
    "Essentially, the rover has to decide between two options: Take the longer path with the bonus points from the experiment, or take a shorter path without bonus points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 3.1 (3 points)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform any Q-learning, the game world states need to be represented as some type of data structure. For our grid world, a 2D array is well suited. The values inside the array represent the reward the agent receives for reaching each state by performing an action. \n",
    "\n",
    "**a)** Create a 2-dimensional Numpy array with the dimensions 8x8 and initialise all fields with 0.    \n",
    "\n",
    "**b)** Represent the obstacles in the grid world as reward values in our states array. All states without obstacles should have a reward of -1. Set every state with a big rock to have a reward of -200. Set the reward for the target state (1,1) to 100, and the reward for the bonus state (6,1) to 50. The states with larger rock fields (marked by pink/bright red) should all have a reward of -50. \n",
    "Create a method with which we can reset the values of the states-array to the defined configuration. This method will be used later to **reset** the states rewards after each training episode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create the 2D 8x8 numpy array. \n",
    "# Hint: numpy 2D array indexing is in the order (row, column)\n",
    "# ...\n",
    "\n",
    "# Define the method to reset the states array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 3.3 (2 points)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rover can perform 4 different actions (left/right/up/down). Every action is represented as a number. \n",
    "\n",
    "| Number   | Action |\n",
    "|:-------:|:------------|\n",
    "| 0 | left |\n",
    "| 1 | right |\n",
    "| 2 | up |\n",
    "| 3 | down |\n",
    "\n",
    "So far, we defined the states and the available actions. In every reachable state in our grid world, executing any of the 4 actions leads to a transition to the next state. The next state can be a different state or the same state again (e.g. when the rover is at row 0 and tries to go further up, it does not move).\n",
    "\n",
    "As you know from the lecture and the tutorial, during the learning phase, we have a table with $\\hat{Q}$-Values. There is one entry for every state-action pair. These values are updated during the learning phase in the hope that the agent's estimate $\\hat{Q}$ converges to the actual $Q$.    \n",
    "**a)** What are the requirements that have to be fullfilled so that we can expect $\\hat{Q}$ to actually converge to $Q$, using the algorithm from the lecture slides?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer:* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**b)** Now, let's implement the $\\hat{Q}$-table for our agent. There are 8x8 states and 4 actions. Create a 3-dimensional numpy-array of floats with dimensions 8x8x4 and initialise all fields with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 3.4 (1 points)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take another look at the Q-Learning algorithm in the lecture (ML-12 page 16). Is there anything which would be a problem for us if we would try to implement the Q-Learning algorithm exactly like on that page?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer:* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 3.5 (2 points)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact strategy what action to select is not directly defined by the algorithm. The lecture presents two possible strategies: choosing the action which has the highest $\\hat{Q}$ value in this state (greedy/'exploitation'), or choosing based on probabilities influenced by a factor k ('exploration').    \n",
    "For this implementation, we will use *both* a greedy and a randomized approach.\n",
    "\n",
    "Why do we need both exploration and exploitation? Can we not always choose the action that maximizes $\\hat{Q}(s,a)$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer:* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 3.6 (7 points)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a method that performs *one* training *episode*. An *episode* starts with the rover at its starting point **s**, given by an input parameter (e.g. a tuple 'startposition'). The method shall also receive input variables *epsilon* ($ \\epsilon $, float), *discountFactor* (float, represents discount $\\gamma$), and *learningrate* (float). A proposed basic outline of the method is given as pseudocode. \n",
    "\n",
    "Two things are noticably different compared to the \"standard\" Q-Learning algorithm:\n",
    "1. When a state without an obstacle is visited, the reward of that state shall be set to -10 (after all the other calculations). This is done to disencourage visiting that state again.\n",
    "\n",
    "2. The lecture gives the following formula for updating $\\hat{Q}$: $$\\hat{Q}(s_{old},a) = r + \\gamma * max_{a'}\\hat{Q}(s_{new},a')$$ For use in our scenario, we add a *learning rate* $l$, such that our formula becomes: $$\\hat{Q}(s_{old},a) = (1-l)* \\hat{Q}(s_{old},a) + l * (r + \\gamma * max_{a'}\\hat{Q}(s_{new},a'))$$ Use the formula that uses the learning rate for this implementation.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# oneEpisode(startposition, epsilon, discountFactor, learningRate)\n",
    "    # reset the states array\n",
    "    # set s = startposition\n",
    "    # Do until position (1,1) is reached:\n",
    "        # Strategy to select an action a:\n",
    "            # Generate random float between 0 and 1\n",
    "            # If the generated float is larger than epsilon, choose the action with the highest Q^-Value\n",
    "            # If the generated float is smaller than epsilon, choose a random action\n",
    "            \n",
    "        # Execute action a, receive new state s' and reward r (recommended: define a separate method to execute an action and call it here)\n",
    "        # Observe new state s'\n",
    "            # If s' is not the target position, update the table entry for the q_table with the given formula\n",
    "            # If s' IS the target position, set Q^(s,a) = reward r\n",
    "        # Set the reward value for s' in the states-array to -10 if the current reward r is > -10\n",
    "        # Set s = s'\n",
    "        \n",
    "        \n",
    "# You can add your implementation here\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 3.7 (6 Points)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the method from 3.6 completes one training episode. To propagate the $\\hat{Q}$-values in our table, one episode alone is not enough. There are quite a lot of state-action pairs, so training will take some time. Repeatedly performing episodes will slowly propagate the $\\hat{Q}$-values, as the $\\hat{Q}$-table is not being reset after each episode.\n",
    "\n",
    "Because we initialized our $\\hat{Q}$-table with zeros, we have to rely on random actions to explore the world first. There are many different strategies for determining how long we should explore and when to start exploiting the learned $\\hat{Q}$-values. For this assignment, stick to a rather simple approach: The first training episode will be called with epsilon = 1. With every episode, epsilon $\\epsilon$ shall be decreased by the formula $$ \\epsilon = \\epsilon - (1. / \\text{total_number_of_episodes}) $$   \n",
    "Thus, early in training, the oneEpisode method will be called with an epsilon value close to 1. Over many episodes, epsilon is reduced linearly. At the end of training, it will be very close to zero, so the agent will mostly use the learned $\\hat{Q}$-values (exploiting).\n",
    "\n",
    "Your task: Make the agent train 50000 episodes. Use a learning-rate of $0.1$ and use the strategy for epsilon described above. Use a discount-factor $\\gamma$ of $0.8$.\n",
    "\n",
    "Recommended: For every 1000th episode, print out how many actions the agent needed (you can modify the method oneEpisode for that easily).\n",
    "\n",
    "Note: Assuming you defined the $\\hat{Q}$-table (/array) in an earlier codeblock, make sure you reset it *once* before starting the for-loop for training, ie. use 'q_table.fill(0)' to set all existing fields to 0. Otherwise, executing the following codeblock twice would start the second training with an already trained $\\hat{Q}$-table.    \n",
    "Depending on your CPU, 50000 episodes may take a few minutes, that is expected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some code fragments for starting, feel free to change it\n",
    "EPISODES = 50000\n",
    "LEARNING_RATE = 0.1\n",
    "#...\n",
    "\n",
    "#print(\"Start Training\")\n",
    "#for ep in range(EPISODES):\n",
    "    #...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 3.8 (2 points)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, your $\\hat{Q}$-table should contain the learned values. If we now call oneEpisode with epsilon = 0, the rover will take the 'most greedy' path. We only want to see which path the rover takes now, without changing anything about the learned $\\hat{Q}$-values. To achieve this, we simply set the learning rate to 0.\n",
    "\n",
    "Your task: Call oneEpisode again, with the _learning rate_ and _epsilon_ both set to 0 (all other parameters like before). Print out the states-array *after* the episode (do not reset it before printing). Has the rover collected the bonus, or did it take the shorter path with no bonus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Other\n",
    "\n",
    "Sources for the images of rocks used for the scenario image:\n",
    "- https://de.cleanpng.com/png-6z6bab/\n",
    "- https://de.cleanpng.com/png-lazus4/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tips and tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1) Embedding images\n",
    "You can embed images in a jupyter notebook on two ways: <br/>\n",
    "First, you can use the IPython kernel to draw an image everytime the code cell is run like shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/logo.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, you can embed images directly in a Markdown cell as shown below. You can either use markdown syntax or write plain HTML code. Sometimes HTML code is more practical, as you have much finer control over the HTML elements.\n",
    "\n",
    "1. Markdown syntax:\n",
    "![title](images/logo.png)\n",
    "2. HTML syntax\n",
    "<img src=\"images/logo.png\" style=\"width: 70px;\"/>\n",
    "\n",
    "If you are having trouble with **markdown images not refreshing after you change them on disk** you need to refresh your browser. The browser chaches images and the old image is still in the cache."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
